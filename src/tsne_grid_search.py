#!/usr/bin/env python
"""
    This code reduces the dimensionality of a dataset using t-SNE.
    It has several options:
        * --exp_name: Name of the experiment. Useful if you want to do several
        experiments with different target dimensions.
        * --representations_file: Pth file containing the data to reduce. This file
        is one of the representation_files generated  by the code "feature_extraction.py"
        that are usually stored in "../models/MNIST_EXP_ID/CompressedRepresentations/"
        * --target_dim: Dimension wanted for the dimensionality reduction

    It generates various folders in ../models/MNIST_EXP_ID/Projections/ named
    EmbeddedRepresentations_perpVal_lrVal_earlyExVal_dimVal. These folders contains
    five files:
        - labels_ID.pth: List of labels of the different 2D/3D points generated
        by t-SNE.
        - originalImages_ID.pth: List of images representing the different 2D/3D
        points generated by TSNE.
        - representations_ID.pth: List of the 2D/3D points generated by t-SNE.
        - tsne_params.json: Parameters used to obtain the projected points.
        - dataSplits_ID.pth: List indicating if samples i is from the training
        set or the testing set.
"""
import os
import argparse
import numpy as np
from sklearn.manifold import TSNE
import pickle
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
import pickle
from matplotlib import image
import json


def rearangeData(data):
    """
        Function that puts the data of the list of points under the right format:

        Arguments:
        ----------
        data: list
            List where each element is a dict that correspond to one epoch of the training
            process. Each dict contains two keys:
                - 'compressed_representation': List where each element is the
                output of a batch for the given epoch.
                - 'label': List where each element are the labels of the output of a
                batch for a given epoch

        Returns:
        --------
        newData: list
            List containing the data points to plot. The elements of the list
            are dictionaries with two keys:
                - 'compressed_representation': List where each element is one
                output for that epoch
                - 'label': List where each element is the label of the corresponding
                output point in the output list
    """
    newData = []
    for epochData in data:
        newOutput, newOriginalImage, newLabel, newDataSplits = [], [], [], []
        # Labels
        for labelLists in epochData['label']:
            nbSamplesBatch = len(labelLists)# It's the same as len(labelLists[1]), ..,. len(labelLists[9])
            for i in range(nbSamplesBatch):
                newLabel.append(int(labelLists[i]))
        # Auto-encoder representations
        for outputLists in epochData['compressed_representation']:
            for output in outputLists:
                newOutput.append(output.cpu().detach().numpy())
        # Original images
        for original_image_list in epochData['original_image']:
            for originalImage in original_image_list:
                if (type(originalImage) == str):
                    sample_data = np.asarray(Image.open(originalImage))/255.
                    if (len(sample_data.shape) == 3):
                        sample_data = np.moveaxis(sample_data, 2, 0) # Because in pytorch the channel has to be in the first position
                    else:
                        sample_data = sample_data.reshape((1, sample_data.shape[0], sample_data.shape[1]))
                    image = torch.tensor(sample_data)
                    originalImage = image.type("torch.FloatTensor") # To avoid problems with types
                newOriginalImage.append(originalImage.cpu().detach().numpy())
        # Split type of the sample (train or test splits)
        if ('data_split' in epochData):
            for dataSplitLists in epochData['data_split']:
                for dataSplit in dataSplitLists:
                    newDataSplits.append(dataSplit)
        newData.append({'compressed_representation': newOutput, 'original_image': newOriginalImage, 'label': newLabel, 'data_split':newDataSplits})
    return newData



def main():
    # =========================================================================#
    # Construct the argument parser
    ap = argparse.ArgumentParser()
    # Add the arguments to the parser
    ap.add_argument("--exp_name", default='tSNE_GridSearch', help="Name of the experiment", type=str)
    ap.add_argument("--representations_file", required=False, help="Pth file containing the data to reduce", type=str)
    ap.add_argument("--target_dim", required=False, default=2, help="Target dimension of the embedded representation (2 or 3)", type=int)
    ap.add_argument("--use_default_params_tsne", default=False, help="True if want to use the default parameters for t-SNE instead of doing a GridSearch", type=bool)
    args = vars(ap.parse_args())

    # Points file and target dim
    exp_name = args['exp_name']
    representations_file = args['representations_file']
    target_dim = args['target_dim']
    use_default_params_tsne = args['use_default_params_tsne']

    #==========================================================================#
    # Creating the folder with the projections
    # =========================================================================#
    model_folder = '/'.join(representations_file.split('/')[:-2])
    projections_folder = model_folder + '/Projections_{}_'.format(exp_name)
    inc = 0
    while (os.path.isdir(projections_folder + str(inc))):
        inc += 1
    projections_folder = projections_folder + str(inc) + '/'
    os.mkdir(projections_folder)

    #==========================================================================#
    # Parameters for the tgrid search experiment
    # =========================================================================#
    if (use_default_params_tsne):
        perplexities = [30.0]
        early_exaggerations = [12.0]
        learning_rates = [200]
        n_iter = 1000
    else:
        # perplexities = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]
        perplexities = [10, 30, 50]
        # early_exaggerations = [5, 10, 25, 50, 75, 100, 200, 500]
        early_exaggerations = [50, 250, 500]
        # learning_rates = [10, 50, 100, 500, 1000]
        learning_rates = [10, 100, 1000]
        n_iter = 3000


    #==========================================================================#
    #==========================================================================#
    #==========================================================================#
    for perplexity in perplexities:
        for early_exaggeration in early_exaggerations:
            for learning_rate in learning_rates:
                parameters_dict = {
                                    'perplexity': perplexity,
                                    'early_exaggeration': early_exaggeration,
                                    'learning_rate': learning_rate,
                                    'n_iter': n_iter,
                                    'n_jobs': 4
                                  }

                # Loading the representations
                with open(representations_file, "rb") as fp:   # Unpickling
                    data = pickle.load(fp)

                # Seing if there is any data to process
                noData = True
                for element in data:
                    if len(element['compressed_representation']) > 0:
                        noData = False
                        break
                if (noData):
                    print("The file {} does not contain any compressed representations to reduce".format(representations_file))
                else:
                    # Rearanging data
                    data = rearangeData(data)

                    final_representations = data[-1] # To only get the representations obtained
                    # at the last epoch

                    #==========================================================================#
                    # Applying t-SNE
                    representation_list = []
                    for representation in final_representations['compressed_representation']:
                        if (len(representation.shape) == 3): # This is needed becayse
                        # the input of t-SNE should be a vector
                            representation_list.append(representation.reshape(representation.shape[0]*representation.shape[1]*representation.shape[2]))
                        elif (len(representation.shape) == 1):
                            representation_list.append(representation)
                        else:
                            raise ValueError("Wrong dimensions for the representations: {}".format(representation.shape))
                    representation_list = np.array(representation_list)

                    print("=======> Starting TSNE")
                    if (target_dim == 3):
                        tsneInstance = TSNE(n_components=3, perplexity=parameters_dict['perplexity'], early_exaggeration=parameters_dict['early_exaggeration'], learning_rate=parameters_dict['learning_rate'], n_jobs=parameters_dict['n_jobs'])
                    elif (target_dim == 2):
                        tsneInstance = TSNE(n_components=2, perplexity=parameters_dict['perplexity'], early_exaggeration=parameters_dict['early_exaggeration'], learning_rate=parameters_dict['learning_rate'], n_jobs=parameters_dict['n_jobs'])
                    else:
                        raise ValueError("Dimension {} for the embedded representation is not valid".format(target_dim))
                    embedded_representations = tsneInstance.fit_transform(representation_list)
                    print("The method converged in {} iterations".format(tsneInstance.n_iter))
                    print("=======> Ending TSNE")

                    # Creating the folder where we are going to store the different files of the
                    # embedded representations
                    inc = 0
                    folderName = projections_folder +\
                                '/EmbeddedRepresentations_perp{}_lr{}_earlyEx{}_dim{}'.format(parameters_dict['perplexity'],\
                                                                                              parameters_dict['learning_rate'],\
                                                                                              parameters_dict['early_exaggeration'],\
                                                                                              target_dim)
                    while (os.path.isdir(folderName + '_' + str(inc))):
                        inc += 1
                    folderName = folderName + '_' + str(inc)
                    os.mkdir(folderName)
                    print("Saving Embedded Representations at: {}".format(folderName))
                    # Saving the embedded points got with T-SNE
                    embReprFileName = folderName + "/representations"
                    inc = 0
                    while os.path.isfile(embReprFileName+'_'+str(inc)+'.pth'):
                        inc +=1
                    embReprFileName += '_'+str(inc)+'.pth'
                    with open(embReprFileName, "wb") as fp:   #Pickling
                        pickle.dump(embedded_representations, fp)
                    # Saving the original images
                    originalImagesFileName = folderName + "/images"
                    inc = 0
                    while os.path.isfile(originalImagesFileName+'_'+str(inc)+'.pth'):
                        inc +=1
                    originalImagesFileName += '_'+str(inc)+'.pth'
                    with open(originalImagesFileName, "wb") as fp:   #Pickling
                        pickle.dump(np.array(final_representations['original_image']), fp)
                    # Saving the labels
                    labelsFileName = folderName + "/labels"
                    inc = 0
                    while os.path.isfile(labelsFileName+'_'+str(inc)+'.pth'):
                        inc +=1
                    labelsFileName += '_'+str(inc)+'.pth'
                    with open(labelsFileName, "wb") as fp:   #Pickling
                        pickle.dump(final_representations['label'], fp)
                    # Saving the data splits of the samples (i.e. if they are train or test samples)
                    dataSplitsFileName = folderName + "/dataSplits"
                    inc = 0
                    while os.path.isfile(dataSplitsFileName+'_'+str(inc)+'.pth'):
                        inc +=1
                    dataSplitsFileName += '_'+str(inc)+'.pth'
                    with open(dataSplitsFileName, "wb") as fp:   #Pickling
                        pickle.dump(final_representations['data_split'], fp)
                    # Saving the parameters used to train TSNE
                    with open(folderName + '/tsne_params.json', 'w') as outfile:
                        json.dump(parameters_dict, outfile)

if __name__=="__main__":
    main()
